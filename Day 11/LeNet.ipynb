{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KOUCcZEBwPEc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 10\n",
        "NUM_CLASSES = 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.1307, ), std=(0.3081, ))\n",
        "        ]),\n",
        "    download=True,\n",
        ")\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.1325, ), std=(0.3105, ))\n",
        "    ]),\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSAFENDIw67b",
        "outputId": "f9d15c63-75a5-4be4-f1c8-13cc92a0378f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 119931204.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 110424515.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 32308342.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7003870.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the LeNet Architecture\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "  def __init__(self, num_classes=NUM_CLASSES):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, padding=0, stride=1),\n",
        "        nn.BatchNorm2d(6),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=0, stride=1),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc = nn.Linear(400, 120)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc1 = nn.Linear(120, 84)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(84, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = self.flatten(out)\n",
        "    out = self.fc(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc1(out)\n",
        "    out = self.relu1(out)\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "3GCy127zysAK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LeNet(NUM_CLASSES).to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "total_step = len(train_dataloader)"
      ],
      "metadata": {
        "id": "z7yKhnNU01lw"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  for i, (images, labels) in enumerate(train_dataloader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    if (i+1) % 400 == 0:\n",
        "      print(f\"Epoch {epoch+1}/{EPOCHS}, Step {i}/{total_step}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X5BOeE11UOh",
        "outputId": "712f95f2-f627-453b-8fc3-7ed60291b991"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Step 399/938, Loss: 0.047678954899311066\n",
            "Epoch 1/10, Step 799/938, Loss: 0.11595113575458527\n",
            "Epoch 2/10, Step 399/938, Loss: 0.017915252596139908\n",
            "Epoch 2/10, Step 799/938, Loss: 0.012542378157377243\n",
            "Epoch 3/10, Step 399/938, Loss: 0.04159318655729294\n",
            "Epoch 3/10, Step 799/938, Loss: 0.03949810564517975\n",
            "Epoch 4/10, Step 399/938, Loss: 0.028746791183948517\n",
            "Epoch 4/10, Step 799/938, Loss: 0.005584072787314653\n",
            "Epoch 5/10, Step 399/938, Loss: 0.045934081077575684\n",
            "Epoch 5/10, Step 799/938, Loss: 0.001006414880976081\n",
            "Epoch 6/10, Step 399/938, Loss: 0.006689663510769606\n",
            "Epoch 6/10, Step 799/938, Loss: 0.0015493565006181598\n",
            "Epoch 7/10, Step 399/938, Loss: 0.0258770938962698\n",
            "Epoch 7/10, Step 799/938, Loss: 0.006097725592553616\n",
            "Epoch 8/10, Step 399/938, Loss: 0.013535972684621811\n",
            "Epoch 8/10, Step 799/938, Loss: 0.02034027688205242\n",
            "Epoch 9/10, Step 399/938, Loss: 0.000592561555095017\n",
            "Epoch 9/10, Step 799/938, Loss: 0.0040889158844947815\n",
            "Epoch 10/10, Step 399/938, Loss: 0.0004984643892385066\n",
            "Epoch 10/10, Step 799/938, Loss: 0.018711881712079048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total =  0\n",
        "\n",
        "  for images, labels in test_dataloader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print(f\"Accuracy of the Network on the test images of size {total} is {correct/total:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIe1PmZP6OMQ",
        "outputId": "df6876f5-8f81-4e64-b109-c4471254fac5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Network on the test images of size 10000 is 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (1, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHh8bcMd7Ree",
        "outputId": "97fff23c-2351-4ffb-e831-9252189f577d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 30, 30]              60\n",
            "       BatchNorm2d-2            [-1, 6, 30, 30]              12\n",
            "              ReLU-3            [-1, 6, 30, 30]               0\n",
            "         MaxPool2d-4            [-1, 6, 15, 15]               0\n",
            "            Conv2d-5           [-1, 16, 11, 11]           2,416\n",
            "       BatchNorm2d-6           [-1, 16, 11, 11]              32\n",
            "              ReLU-7           [-1, 16, 11, 11]               0\n",
            "         MaxPool2d-8             [-1, 16, 5, 5]               0\n",
            "           Flatten-9                  [-1, 400]               0\n",
            "           Linear-10                  [-1, 120]          48,120\n",
            "             ReLU-11                  [-1, 120]               0\n",
            "           Linear-12                   [-1, 84]          10,164\n",
            "             ReLU-13                   [-1, 84]               0\n",
            "           Linear-14                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 61,654\n",
            "Trainable params: 61,654\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.19\n",
            "Params size (MB): 0.24\n",
            "Estimated Total Size (MB): 0.43\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}